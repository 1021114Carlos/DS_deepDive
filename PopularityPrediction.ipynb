{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMJ2Psoq+tztfAnZQ74Wayl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1021114Carlos/DS_deepDive/blob/diving_production/PopularityPrediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BUSSINES PROBLEM: predict the popularity of songs on the Spotify Top 200 Weekly (Global) charts. The features of the songs will be used as input variables, and the song's popularity score will be the target variable for the model. Will dataset project is suitable for Tree-based regression models like Random Forest, Decision Trees, and or XGBoost."
      ],
      "metadata": {
        "id": "t39h2F6UIKod"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O2xCfJemnqZB"
      },
      "outputs": [],
      "source": [
        "url = \"https://ddc-datascience.s3.amazonaws.com/Projects/Project.4-Spotify/Data/Spotify.csv\"\n",
        "!curl -s -I {url}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%magic"
      ],
      "metadata": {
        "id": "sb8IVPNQ3mpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "DypwXFA8oLEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "music_df = pd.read_csv(url)"
      ],
      "metadata": {
        "id": "C40Pl5Xmoalr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "music_df.shape"
      ],
      "metadata": {
        "id": "PwgN86UyoiIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "music_df.describe().T"
      ],
      "metadata": {
        "id": "dKZ3RzUloum0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%%capture\n",
        "music_df"
      ],
      "metadata": {
        "id": "Rf8mxvADpELQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "music_df.isnull()"
      ],
      "metadata": {
        "id": "I0sU1Qwfpq8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "music_df.isnull().sum()*100"
      ],
      "metadata": {
        "id": "NQkJT602qHAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "music_df.isnull().value_counts()"
      ],
      "metadata": {
        "id": "K9Lmj0gIqzhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "music_df.dtypes"
      ],
      "metadata": {
        "id": "_QmUgnNBs1-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **observations about data type**\n",
        ">**From week of highest charting to Chords, we have object type instead of ints or floats. Need to take a look a closer look at these columns**\n"
      ],
      "metadata": {
        "id": "HqJ1g9Ab12Cs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "music_df.info()"
      ],
      "metadata": {
        "id": "cHT6k0QTtQcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Looking for the alphanumeric value in columns with type object.\n",
        "import re\n",
        "\n",
        "pattern = r'\\s+|,+'\n",
        "\n",
        "for col in music_df.columns:\n",
        "    for index, value in music_df[col].iteritems():\n",
        "        if re.search(pattern, str(value)):  # Convert value to string for regex\n",
        "            print(f\"Column: {col}, Index: {index}, Value: {value}\")"
      ],
      "metadata": {
        "id": "4XE2q6RcuSIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# substitue with Null values where whitespaces, commas, exist.\n",
        "\n",
        "for col in music_df.columns:\n",
        "    if pd.api.types.is_string_dtype(music_df[col]):\n",
        "        music_df[col] = music_df[col].str.strip()\n",
        "music_df = music_df.replace({\"\":np.nan})"
      ],
      "metadata": {
        "id": "HvwVnATSdMd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "music_df.isnull().sum()"
      ],
      "metadata": {
        "id": "F2yrxuQ9hniO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "music_df.info()"
      ],
      "metadata": {
        "id": "jqrGJJOabrZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "music_df.isnull().sum().sum()"
      ],
      "metadata": {
        "id": "8pPIjcEYimrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***let's make a copy of the original dataset and drop the null values.***"
      ],
      "metadata": {
        "id": "EbNKn5vKkz7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "music_df_copy = music_df.copy()"
      ],
      "metadata": {
        "id": "lme4cpRlkfC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping Null values from the dataset copy only.\n",
        "music_df_copy = music_df_copy.dropna()"
      ],
      "metadata": {
        "id": "VC5lvQNBlPCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "music_df_copy.isnull().sum()"
      ],
      "metadata": {
        "id": "GzJRqHVvlbPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "music_df_copy.isnull().sum().sum()"
      ],
      "metadata": {
        "id": "jHXGPVzqlm2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "music_df_copy.info()"
      ],
      "metadata": {
        "id": "EZpLf56mlsDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Exploring and modifying columns. dropping columns if necessary.**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TpOOSzqgmddA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Stream column have integer values with commas. Covert Streams column to numerical\n",
        "music_df_copy['Streams'] = music_df_copy['Streams'].str.replace(',', '').astype(int)"
      ],
      "metadata": {
        "id": "v4jL82A0lwKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Denote Week of Highest Charting as WHC and Week of ending charting as WEC.\n",
        "music_df_copy[['WHC_start_date', 'WEC_end_date']] = music_df_copy['Week of Highest Charting'].str.split('--', expand=True)"
      ],
      "metadata": {
        "id": "eW7v23o2nzvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modifying the date format.\n",
        "music_df_copy['WHC_start_date'] = pd.to_datetime(music_df_copy['WHC_start_date'], format='%Y-%m-%d')\n",
        "music_df_copy['WEC_end_date'] = pd.to_datetime(music_df_copy['WEC_end_date'], format='%Y-%m-%d')"
      ],
      "metadata": {
        "id": "MEBA1vj7oBu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Weeks Charted provides similar information as Week of Highest Chrting. drop Week of Highest Charting and Weeks charted.\n",
        "music_df_copy = music_df_copy.drop(columns = ['Week of Highest Charting', \"Weeks Charted\"])"
      ],
      "metadata": {
        "id": "_JuGARkMruVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "music_df_copy[\"Song ID\"].unique()"
      ],
      "metadata": {
        "id": "9bHi9HT_sC4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# There are 1516 unique cells out of 1535. the proportion of cells that have the same identifier is to small to consider it. We'll drop this column next.\n",
        "music_df_copy[\"Song ID\"].nunique()"
      ],
      "metadata": {
        "id": "zeb60DAUsgeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "music_df_copy = music_df_copy.drop(\"Song ID\", axis=1)"
      ],
      "metadata": {
        "id": "Yklw7zkMwJb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's look at index column.\n",
        "music_df_copy[\"Index\"].unique()"
      ],
      "metadata": {
        "id": "qCXeccnbxPad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "music_df_copy[\"Index\"].nunique()"
      ],
      "metadata": {
        "id": "aOug9FEcxbKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# As suspected, Index columns is only to reference the number of rows in the datase. 1,2,...,1556. Let's drop it.\n",
        "music_df_copy = music_df_copy.drop(\"Index\", axis=1)"
      ],
      "metadata": {
        "id": "sat0EUcu03jh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How many artist are there in this dataset\n",
        "music_df_copy[\"Artist\"].nunique()"
      ],
      "metadata": {
        "id": "xyZKv-011kDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "music_df_copy[\"Artist\"].value_counts()"
      ],
      "metadata": {
        "id": "Ma17YcCV2Pp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's normalize each time a artist is found in the rows of the artist column.\n",
        "artist_counts = (music_df_copy['Artist'].value_counts(normalize=True) * 100).round(3)\n",
        "artist_info_df = pd.DataFrame({'Artist Name': artist_counts.index, 'Percentage (%)': artist_counts.values})\n",
        "artist_info_df"
      ],
      "metadata": {
        "id": "0aEao25WsQY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "artist_info_df.dtypes"
      ],
      "metadata": {
        "id": "sGTvR7p8AT8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's consider Popularity of songs. convert Popularity column to numeric.\n",
        "music_df_copy[\"Popularity\"] = pd.to_numeric(music_df_copy[\"Popularity\"])\n",
        "pd.DataFrame(music_df_copy[music_df_copy[\"Popularity\"] > 90][\"Song Name\"])"
      ],
      "metadata": {
        "id": "3khtyfvxuCYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Let's look at the data visually.**"
      ],
      "metadata": {
        "id": "tEaZazHkcLxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(17, 12))\n",
        "plt.title('Top 25 artists by number of genres', y = 1.05)\n",
        "ax = fig.subplots()\n",
        "ax.set_ylabel(\"Genre\")\n",
        "ax.set_xlabel(\"Artist\")\n",
        "music_df_copy[\"Artist\"].value_counts()[:25].plot(ax=ax, kind=\"bar\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bhpj-xc3ZUEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Who are the most popular artists.\n",
        "top_artists = music_df_copy['Artist'].value_counts().head(20)\n",
        "\n",
        "plt.figure(figsize=(14, 8))\n",
        "top_artists.plot(kind='bar', color='skyblue', edgecolor='black')\n",
        "plt.title(\"Top 20 Most Popular Artists\", y = 1.25)\n",
        "plt.xlabel(\"Artist\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lI8_JCXzlJBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_songs = music_df_copy.sort_values(by='Streams', ascending=False).head(50)\n",
        "\n",
        "# Separate data for plotting\n",
        "song_names = top_songs['Song Name'].tolist()\n",
        "stream_counts = top_songs['Streams'].tolist()\n",
        "\n",
        "plt.figure(figsize=(15, 8))\n",
        "\n",
        "plt.bar(song_names, stream_counts, color='lightcoral', edgecolor='black')\n",
        "\n",
        "plt.title(\"Popularity of top 50 Songs\")\n",
        "plt.xlabel(\"Song\")\n",
        "plt.ylabel(\"Streams\")\n",
        "plt.xticks(rotation=90, ha='right')  # Rotate x-axis labels for better readability\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6plDAsOUgCOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(x=music_df_copy.Streams, y=music_df_copy.Popularity, s=50)\n",
        "\n",
        "plt.xlabel('Streaming Frequency')\n",
        "plt.ylabel('Popularity');"
      ],
      "metadata": {
        "id": "-Idynd3FgUzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Based on this observation, I might not need these columns.\n",
        "\n",
        "corr = music_df_copy.corr()[['Popularity']].sort_values(by='Popularity', ascending=False)\n",
        "plt.figure(figsize=(8, 4))\n",
        "heatmap = sns.heatmap(corr, annot=True, cmap='Greens');\n",
        "heatmap.set_title('HCP, NTC, Streams columns correlated features to Popularity', fontdict={'fontsize':18}, pad=16);"
      ],
      "metadata": {
        "id": "TYeeUr2MgwOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20, 15))\n",
        "plt.title('Popularity trend over different features', y = 1.05)\n",
        "Xfeatures = [\"Highest Charting Position\", \"Number of Times Charted\", \"Song Name\", \"Streams\", \"Artist\", \"Artist Followers\", \"Genre\"]\n",
        "Yfeature = \"Popularity\"\n",
        "cols = 4\n",
        "rows = len(Xfeatures)//cols + 1\n",
        "for idx, feat in enumerate(Xfeatures):\n",
        "  plt.subplot(rows,cols,idx+1)\n",
        "  sub_group = music_df_copy.groupby(feat)\n",
        "  Yfeature = sub_group.mean()[\"Popularity\"] # Mean popularity is good enough to estimate and visualize\n",
        "  sns.scatterplot(x=Yfeature.index, y=Yfeature);"
      ],
      "metadata": {
        "id": "C1I_TIBRo7s0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Dropping columns. These columns are not features that contribute to the popularity of a song**\n",
        " * Highest Charting\n",
        " * Number of times Charted\n",
        " * Song Names"
      ],
      "metadata": {
        "id": "QTKszwcnz-6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "music_df_copy = music_df_copy.drop(columns=[\"Highest Charting Position\", \"Number of Times Charted\", \"Song Name\"])"
      ],
      "metadata": {
        "id": "ogxlkzfpsw2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instead of one-hot encoding, obtain every element and count how popular the genre is.\n",
        "# Concatenate and use column as a feature.\n",
        "genre_count = everyGenre[\"Genre\"].explode().value_counts().reset_index(name='Genre Count')\n",
        "genre_count.columns = ['Genre', 'Genre Count']  # Rearrange columns for clarity\n",
        "\n",
        "genre_count"
      ],
      "metadata": {
        "id": "JBD7IhLQ3oNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's evaluate popular genres\n",
        "# everyGenre = music_df_copy[[\"Genre\"]]\n",
        "\n",
        "# def count_unique_items(list_of_items):\n",
        "#   item_counts = {}\n",
        "\n",
        "#   for item in list_of_items:\n",
        "#     # If the item is already in the dictionary, increment its count\n",
        "#     if item in item_counts:\n",
        "#       item_counts[item] += 1\n",
        "#     # Otherwise, add the item to the dictionary with a count of 1\n",
        "#     else:\n",
        "#       item_counts[item] = 1\n",
        "\n",
        "#   return item_counts\n",
        "\n",
        "# everyGenre[\"Genre\"] = everyGenre[\"Genre\"].apply(lambda x: [i.strip() for i in x[1:-1].split(\", \")])\n",
        "# # Flatten all lists in the \"Genre\" column into a single list\n",
        "# all_items = sum(everyGenre[\"Genre\"], [])\n",
        "\n",
        "# # Count occurrences of each unique item\n",
        "# item_counts = count_unique_items(all_items)\n",
        "\n",
        "# # Convert the item counts into a DataFrame\n",
        "# total_counts = pd.DataFrame.from_dict(item_counts, orient='index', columns=['Count'])\n",
        "\n",
        "# # Sort the DataFrame by count in descending order\n",
        "# genre_total = total_counts.sort_values(by='Count', ascending=False)\n",
        "# genre_total"
      ],
      "metadata": {
        "id": "NEiV_dBlNfxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Looking at  the top Genres. Let's keep this column for now.\n",
        "genre_count[genre_count[\"Genre Count\"] > 80]"
      ],
      "metadata": {
        "id": "1Mf9KzqfN688"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "music_df_copy = pd.concat([music_df_copy, genre_count], axis=1)"
      ],
      "metadata": {
        "id": "xD-Tx8ZCrr6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "artist_count = music_df_copy[\"Artist\"].explode().value_counts().reset_index(name='Artist Count')\n",
        "artist_count.columns = ['Artist', 'Artist Count']  # Rearrange columns for clarity\n",
        "\n",
        "artist_count"
      ],
      "metadata": {
        "id": "LSy0xZyV1Ruk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use artist count as a feature as well.\n",
        "music_df_copy = pd.concat([music_df_copy, artist_count], axis=1)"
      ],
      "metadata": {
        "id": "6FnYGHkMBQhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "music_df_copy"
      ],
      "metadata": {
        "id": "iV6hvsblBY_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *Let's drop the NaN*"
      ],
      "metadata": {
        "id": "wT_BsYHHy_M7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "music_df_copy = music_df_copy.dropna()"
      ],
      "metadata": {
        "id": "ewXKhoySry0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Now Let's investigate the columns with Speechness, Energy, Loudness, etc"
      ],
      "metadata": {
        "id": "KWM4bIv-zN5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# trying to graph the features return an error, caused by the the datatype.\n",
        "# convert from object to float\n",
        "music_df_copy[['Danceability', 'Energy', 'Loudness', 'Speechiness', 'Acousticness', 'Liveness', 'Tempo', 'Valence']] = music_df_copy[['Danceability', 'Energy', 'Loudness', 'Speechiness', 'Acousticness', 'Liveness', 'Tempo', 'Valence']].astype(float);"
      ],
      "metadata": {
        "id": "pFCidVfo3B1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "music_df_copy"
      ],
      "metadata": {
        "id": "YCrwWhJa6-_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_style('darkgrid')\n",
        "matplotlib.rcParams['font.size'] = 14\n",
        "matplotlib.rcParams['figure.figsize'] = (16, 8)\n",
        "matplotlib.rcParams['figure.facecolor'] = '#00000000'"
      ],
      "metadata": {
        "id": "p2bHTAHcJQy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tem_music_df_copy = music_df_copy.head(100)"
      ],
      "metadata": {
        "id": "_3mcrJsROMUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(temp_music_df_copy.Streams, temp_music_df_copy.Danceability, 's-b')\n",
        "plt.plot(temp_music_df_copy.Streams, temp_music_df_copy.Energy, 'o--r')\n",
        "\n",
        "plt.xlabel('streaming frequency')\n",
        "plt.ylabel('Danceability/Energy');\n",
        "\n",
        "plt.title(\"Danceability & Energy relation\")\n",
        "plt.legend(['Danceability', 'Energy']);"
      ],
      "metadata": {
        "id": "w5d8cSs-08If"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(temp_music_df_copy.Acousticness, temp_music_df_copy.Danceability, 's-b')\n",
        "plt.plot(temp_music_df_copy.Acousticness, temp_music_df_copy.Energy, 'o--r')\n",
        "\n",
        "plt.xlabel('Acousticness')\n",
        "plt.ylabel('Danceability');\n",
        "\n",
        "plt.title(\"Danceability &E acoustics relation\")\n",
        "plt.legend(['Danceability', 'acoustics']);"
      ],
      "metadata": {
        "id": "yyUSlZkz0JfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(x=temp_music_df_copy.Streams,\n",
        "                y=temp_music_df_copy.Valence,\n",
        "                s=100);\n",
        "\n",
        "plt.xlabel('Num of times streamed')\n",
        "plt.ylabel('Valence(Happy, cheerful)');\n",
        "plt.title(\"Streams based on Valence\");"
      ],
      "metadata": {
        "id": "i0mgO74OPp6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "fig,ax = plt.subplots(figsize=(20, 5))\n",
        "sns.despine(fig, left=True, bottom=True)\n",
        "sns.set_context(rc={\"lines.linewidth\": 3})\n",
        "\n",
        "features = [\"Acousticness\",\"Danceability\",\"Energy\",\"Speechiness\",\"Liveness\",\"Valence\"]\n",
        "ax.set_ylabel('Measure')\n",
        "ax.set_xlabel('Popularity')\n",
        "ax.set_title('Audio characteristic trend over years', y = 1.05)\n",
        "for col in features:\n",
        "    x = temp_music_df_copy.groupby(\"Popularity\")[col].mean()\n",
        "    ax= sns.lineplot(x=x.index,y=x,label=col)"
      ],
      "metadata": {
        "id": "pnm1oa8YRgSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *Daceability, Energy, Valence are strong features for popularity*"
      ],
      "metadata": {
        "id": "HaHw9mD8SdM3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20, 15))\n",
        "plt.title('Popularity trend over different features', y = 1.05)\n",
        "Xfeatures = [\"Danceability\", \"Acousticness\", \"Loudness\", \"Energy\", \"Liveness\", \"Valence\", \"Genre Count\", \"Artist Count\"]\n",
        "Yfeature = \"Popularity\"\n",
        "cols = 4\n",
        "rows = len(Xfeatures)//cols + 1\n",
        "for idx, feat in enumerate(Xfeatures):\n",
        "  plt.subplot(rows,cols,idx+1)\n",
        "  sub_group = music_df_copy.groupby(feat)\n",
        "  Yfeature = sub_group.mean()[\"Popularity\"]\n",
        "  sns.scatterplot(x=Yfeature.index, y=Yfeature)"
      ],
      "metadata": {
        "id": "qyRT_9OSR7ib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## time to process the data"
      ],
      "metadata": {
        "id": "YsJqsq03VAkA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "music_df_copy"
      ],
      "metadata": {
        "id": "LHJ0j1ffVdeb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import plotly.express as px"
      ],
      "metadata": {
        "id": "TYGxcVtHYeil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting features based on graphs observations.\n",
        "features_selected = music_df_copy[[\"Energy\", \"Valence\", \"Danceability\", \"Acousticness\", \"Streams\", \"Artist Followers\", \"Genre Count\", \"Artist Count\"]]\n",
        "target = music_df_copy[\"Popularity\"]"
      ],
      "metadata": {
        "id": "Et1WVg5OWjid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *Decision tree*"
      ],
      "metadata": {
        "id": "-nkXtMO2Z8Xq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = features_selected\n",
        "y = target\n",
        "\n",
        "results = {}\n",
        "\n",
        "numLoops = 100\n",
        "\n",
        "for i in range(1,6):\n",
        "  mean_error = np.zeros(numLoops)\n",
        "  for idx in range(0,numLoops):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, shuffle = True, )\n",
        "    model = DecisionTreeRegressor(max_depth = i)\n",
        "    model.fit(X_train,y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    mean_error[idx] = mean_squared_error(y_test, y_pred)\n",
        "    results[f\"Depth = {i}\"] = mean_error\n",
        "\n",
        "print(f'Decision Tree RMSE: {np.sqrt(mean_error).mean()}')"
      ],
      "metadata": {
        "id": "lFWrFaXMTWI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Random Forest*"
      ],
      "metadata": {
        "id": "iuRWqPiJF8PW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "\n",
        "numLoops = 100\n",
        "\n",
        "for i in range(1,6):\n",
        "  mean_error = np.zeros(numLoops)\n",
        "  for idx in range(0,numLoops):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, shuffle = True, )\n",
        "    random_forest_model = RandomForestRegressor(max_depth = i)\n",
        "    model.fit(X_train,y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    mean_error[idx] = mean_squared_error(y_test, y_pred)\n",
        "    results[f\"Depth = {i}\"] = mean_error\n",
        "\n",
        "print(f'Random Forest RMSE: {np.sqrt(mean_error).mean()}')"
      ],
      "metadata": {
        "id": "qRGReXuqF7Ox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *XGBRegresson*"
      ],
      "metadata": {
        "id": "oyza7B0abAUS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "\n",
        "# Define numLoops\n",
        "numLoops = 100\n",
        "\n",
        "for column in X.columns:\n",
        "    X[column] = pd.to_numeric(X[column], errors='coerce')\n",
        "\n",
        "# Perform grid search\n",
        "for i in range(1, 6):\n",
        "    mean_error = np.zeros(numLoops)\n",
        "    for idx in range(0, numLoops):\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
        "        xgb_model = XGBRegressor(max_depth=i)\n",
        "        xgb_model.fit(X_train, y_train)\n",
        "        y_pred_xgb = xgb_model.predict(X_test)\n",
        "        mean_error[idx] = mean_squared_error(y_test, y_pred_xgb)\n",
        "    results[f\"Depth = {i}\"] = mean_error\n",
        "\n",
        "# Print results\n",
        "for depth, error in results.items():\n",
        "    print(f'XGBRegressor RMSE (Depth={depth}): {np.sqrt(error).mean()}')"
      ],
      "metadata": {
        "id": "fOl03jCPYO4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "importances = model.feature_importances_\n",
        "\n",
        "# Create a DataFrame to display feature importances\n",
        "feature_importances_rf = pd.DataFrame({'Feature': X_train.columns, 'Importance': importances})\n",
        "feature_importances_rf = feature_importances_rf.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Display feature importances\n",
        "print(feature_importances_rf)"
      ],
      "metadata": {
        "id": "Pql6-39NihDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_importances_rf = feature_importances_rf.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "feature_importances_rf = feature_importances_rf[::-1]\n",
        "\n",
        "# Plot the feature importance values using Plotly Express\n",
        "fig = px.bar(feature_importances_rf, x='Importance', y='Feature', orientation='h',\n",
        "             title='Feature Importance Plot for Random Forest Model',\n",
        "             labels={'Importance': 'Importance', 'Feature': 'Feature'})\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "56QldqExauNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "importances = xgb_model.feature_importances_\n",
        "\n",
        "# Create a DataFrame to display feature importances\n",
        "feature_importances_xgb = pd.DataFrame({'Feature': X_train.columns, 'Importance': importances})\n",
        "feature_importances_xgb = feature_importances_xgb.sort_values(by='Importance', ascending=False)"
      ],
      "metadata": {
        "id": "8iE3DAk6krvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_importances_xgb = feature_importances_xgb.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "feature_importances_xgb = feature_importances_xgb[::-1]\n",
        "\n",
        "# Plot the feature importance values using Plotly Express\n",
        "fig = px.bar(feature_importances_xgb, x='Importance', y='Feature', orientation='h',\n",
        "             title='Feature Importance Plot for XG Boost Model',\n",
        "             labels={'Importance': 'Importance', 'Feature': 'Feature'})\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "ArG1b0x7iLhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cWRUhOq7jxPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion: Based on the RMSE values, XGBoost with a depth of 2 achieved the best performance in predicting song popularity (RMSE: 8.0541) followed by Random Forest (RMSE: 10.52) and Decision Tree (RMSE: 10.97). This indicates that XGBoos is a more suitable model for this dataset."
      ],
      "metadata": {
        "id": "8KuWHk3GJuUx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kbFokyMeK52s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}